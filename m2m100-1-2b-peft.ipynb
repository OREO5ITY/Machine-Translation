{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9089923,"sourceType":"datasetVersion","datasetId":5485117}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q datasets evaluate nltk sacremoses peft","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import wandb\n# Disable wandb logging\nwandb.init(mode=\"disabled\")","metadata":{"execution":{"iopub.status.busy":"2024-08-03T20:45:51.043218Z","iopub.execute_input":"2024-08-03T20:45:51.043570Z","iopub.status.idle":"2024-08-03T20:45:52.451660Z","shell.execute_reply.started":"2024-08-03T20:45:51.043540Z","shell.execute_reply":"2024-08-03T20:45:52.450723Z"},"trusted":true},"execution_count":1,"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":""},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nfrom datasets import Dataset\nfrom tqdm import tqdm\nfrom nltk.translate.bleu_score import sentence_bleu\nimport nltk\nfrom sklearn.model_selection import train_test_split\nfrom transformers import (M2M100ForConditionalGeneration,\n                          M2M100Tokenizer,\n                          Seq2SeqTrainingArguments, Seq2SeqTrainer,\n                          Trainer,\n                          TrainingArguments,\n                          pipeline,\n                          EarlyStoppingCallback)\nfrom peft import get_peft_model, LoraConfig, TaskType","metadata":{"execution":{"iopub.status.busy":"2024-08-03T20:45:52.453183Z","iopub.execute_input":"2024-08-03T20:45:52.453571Z","iopub.status.idle":"2024-08-03T20:46:00.008683Z","shell.execute_reply.started":"2024-08-03T20:45:52.453546Z","shell.execute_reply":"2024-08-03T20:46:00.007857Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-08-03 20:45:56.497131: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-03 20:45:56.497193: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-03 20:45:56.498636: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"# Download the necessary NLTK data\nnltk.download('punkt')","metadata":{"execution":{"iopub.status.busy":"2024-08-03T20:46:00.009731Z","iopub.execute_input":"2024-08-03T20:46:00.010440Z","iopub.status.idle":"2024-08-03T20:46:00.121235Z","shell.execute_reply.started":"2024-08-03T20:46:00.010413Z","shell.execute_reply":"2024-08-03T20:46:00.120360Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"# Define compute_metrics function for BLEU score\ndef compute_metrics(eval_preds):\n    preds, labels = eval_preds\n    if isinstance(preds, tuple):\n        preds = preds[0]\n    \n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n    \n    # Compute BLEU scores\n    bleu_scores = []\n    for pred, label in zip(decoded_preds, decoded_labels):\n        reference = nltk.word_tokenize(label)\n        candidate = nltk.word_tokenize(pred)\n        bleu_score = sentence_bleu([reference], candidate, weights=(0.5, 0.5))  # 2-gram BLEU\n        bleu_scores.append(bleu_score)\n    \n    return {\"bleu\": sum(bleu_scores) / len(bleu_scores)}","metadata":{"execution":{"iopub.status.busy":"2024-08-03T20:46:00.123266Z","iopub.execute_input":"2024-08-03T20:46:00.123537Z","iopub.status.idle":"2024-08-03T20:46:00.130334Z","shell.execute_reply.started":"2024-08-03T20:46:00.123513Z","shell.execute_reply":"2024-08-03T20:46:00.129425Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Prepair Model and Tokenizer","metadata":{}},{"cell_type":"code","source":"# Load the pre-trained model and tokenizer\nmodel_name = \"facebook/m2m100_1.2B\"\nmodel = M2M100ForConditionalGeneration.from_pretrained(model_name)\ntokenizer = M2M100Tokenizer.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T20:46:00.131513Z","iopub.execute_input":"2024-08-03T20:46:00.131853Z","iopub.status.idle":"2024-08-03T20:46:03.415208Z","shell.execute_reply.started":"2024-08-03T20:46:00.131822Z","shell.execute_reply":"2024-08-03T20:46:03.414336Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n","output_type":"stream"}]},{"cell_type":"code","source":"# Set the source and target languages\ntokenizer.src_lang = \"th\"  # Northern Thai (you may need to check the exact code)\ntokenizer.tgt_lang = \"th\"   # Central Thai","metadata":{"execution":{"iopub.status.busy":"2024-08-03T20:46:03.416323Z","iopub.execute_input":"2024-08-03T20:46:03.416607Z","iopub.status.idle":"2024-08-03T20:46:03.421746Z","shell.execute_reply.started":"2024-08-03T20:46:03.416582Z","shell.execute_reply":"2024-08-03T20:46:03.420818Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Define LoRA Config\npeft_config = LoraConfig(\n    task_type=TaskType.SEQ_2_SEQ_LM,\n    r=8,\n    lora_alpha=32,\n    lora_dropout=0.1,\n    target_modules=\"all-linear\", #[\"q_proj\", \"v_proj\"]\n)\n\n# Apply LoRA to the model\nmodel = get_peft_model(model, peft_config)\nmodel.print_trainable_parameters()","metadata":{"execution":{"iopub.status.busy":"2024-08-03T20:46:03.422858Z","iopub.execute_input":"2024-08-03T20:46:03.423177Z","iopub.status.idle":"2024-08-03T20:46:04.106603Z","shell.execute_reply.started":"2024-08-03T20:46:03.423153Z","shell.execute_reply":"2024-08-03T20:46:04.105520Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"trainable params: 11,796,480 || all params: 1,251,266,560 || trainable%: 0.9428\n","output_type":"stream"}]},{"cell_type":"code","source":"# Tokenize the dataset\ndef tokenize_function(examples):\n    inputs = tokenizer(examples[\"Northern\"], truncation=True, padding=\"max_length\", max_length=128)\n    with tokenizer.as_target_tokenizer():\n        targets = tokenizer(examples[\"Central\"], truncation=True, padding=\"max_length\", max_length=128)\n    return {\n        \"input_ids\": inputs.input_ids,\n        \"attention_mask\": inputs.attention_mask,\n        \"labels\": targets.input_ids,\n    }","metadata":{"execution":{"iopub.status.busy":"2024-08-03T20:46:04.107811Z","iopub.execute_input":"2024-08-03T20:46:04.108191Z","iopub.status.idle":"2024-08-03T20:46:04.114355Z","shell.execute_reply.started":"2024-08-03T20:46:04.108157Z","shell.execute_reply":"2024-08-03T20:46:04.113402Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## Load Train Data","metadata":{}},{"cell_type":"code","source":"# Load the dataset\ndf = pd.read_csv('/kaggle/input/north-translation/train.csv')\ndataset = Dataset.from_pandas(df)\n\n# Split the dataset\ntrain_test = dataset.train_test_split(test_size=0.1)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T20:46:04.115546Z","iopub.execute_input":"2024-08-03T20:46:04.115920Z","iopub.status.idle":"2024-08-03T20:46:04.176248Z","shell.execute_reply.started":"2024-08-03T20:46:04.115887Z","shell.execute_reply":"2024-08-03T20:46:04.175308Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"tokenized_train = train_test['train'].map(tokenize_function, batched=True)\ntokenized_test = train_test['test'].map(tokenize_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T20:46:04.179118Z","iopub.execute_input":"2024-08-03T20:46:04.179407Z","iopub.status.idle":"2024-08-03T20:46:10.450368Z","shell.execute_reply.started":"2024-08-03T20:46:04.179382Z","shell.execute_reply":"2024-08-03T20:46:10.449479Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1440 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba079d8c441b448f9132ca2e74870c20"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4016: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/160 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ffd10ece50e9482181af7acf04a5dcd5"}},"metadata":{}}]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"# Set up training arguments\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=\"./results\",\n    eval_strategy= \"epoch\", #\"steps\",\"epoch\"\n#     eval_steps = 20,\n    save_strategy = \"epoch\", #\"steps\",\n#     save_steps = 20,\n    logging_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=2,\n    per_device_eval_batch_size=2,\n    weight_decay=0.01,\n    save_total_limit=1,\n    num_train_epochs=30,\n    predict_with_generate=True,\n#     fp16=torch.cuda.is_available(),  # Enable mixed precision training if available\n    metric_for_best_model=\"bleu\",\n    load_best_model_at_end=True,\n)\n\n# Define the EarlyStoppingCallback\nearly_stopping = EarlyStoppingCallback(\n    early_stopping_patience=3, # Number of evaluations with no improvement to wait before stopping\n    early_stopping_threshold=0.01 # Minimum change to qualify as an improvement\n)\n\n# Initialize the trainer\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train,\n    eval_dataset=tokenized_test,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n    callbacks=[early_stopping],\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T20:46:10.451565Z","iopub.execute_input":"2024-08-03T20:46:10.451851Z","iopub.status.idle":"2024-08-03T20:46:12.133087Z","shell.execute_reply.started":"2024-08-03T20:46:10.451825Z","shell.execute_reply":"2024-08-03T20:46:12.132144Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Train the model\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-08-04T00:45:26.949558Z","iopub.execute_input":"2024-08-04T00:45:26.950464Z","iopub.status.idle":"2024-08-04T01:43:54.775370Z","shell.execute_reply.started":"2024-08-04T00:45:26.950430Z","shell.execute_reply":"2024-08-04T01:43:54.774379Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1440' max='10800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 1440/10800 58:24 < 6:20:13, 0.41 it/s, Epoch 4/30]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Bleu</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>5.224300</td>\n      <td>5.284739</td>\n      <td>0.629929</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>5.212700</td>\n      <td>5.278725</td>\n      <td>0.634075</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>5.198200</td>\n      <td>5.275057</td>\n      <td>0.639104</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>5.188700</td>\n      <td>5.269382</td>\n      <td>0.646211</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1440, training_loss=5.205973222520616, metrics={'train_runtime': 3506.7219, 'train_samples_per_second': 12.319, 'train_steps_per_second': 3.08, 'total_flos': 4954874928168960.0, 'train_loss': 5.205973222520616, 'epoch': 4.0})"},"metadata":{}}]},{"cell_type":"code","source":"# Save the fine-tuned model\npeft_model_id = \"M2M100_1.2B_peft\"\ntrainer.model.save_pretrained(peft_model_id)\ntokenizer.save_pretrained(peft_model_id)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T23:27:28.653968Z","iopub.status.idle":"2024-08-03T23:27:28.654300Z","shell.execute_reply.started":"2024-08-03T23:27:28.654133Z","shell.execute_reply":"2024-08-03T23:27:28.654147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inference","metadata":{}},{"cell_type":"code","source":"model_name = \"facebook/m2m100_1.2B\"\nmodel_path = 'kaggle/working/M2M100_1.2B_peft'\n\ndef load_peft_model(model_path):\n    # Load the base model\n    base_model = M2M100ForConditionalGeneration.from_pretrained(model_name)\n\n    # Load the PEFT configuration\n    peft_config = PeftConfig.from_pretrained(model_path)\n\n    # Load the PEFT model\n    model = PeftModel.from_pretrained(base_model, model_path)\n\n    return model\n\n# Load the saved model\nmodel = load_peft_model(model_path)\ntokenizer = M2M100Tokenizer.from_pretrained(model_path)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T23:27:28.656096Z","iopub.status.idle":"2024-08-03T23:27:28.656431Z","shell.execute_reply.started":"2024-08-03T23:27:28.656269Z","shell.execute_reply":"2024-08-03T23:27:28.656283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Move model to GPU if available\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel = model.to(device)\nmodel.eval()\n\n# Batch inference function\ndef batch_translate(texts, batch_size=2):\n    all_translations = []\n    \n    for i in tqdm(range(0, len(texts), batch_size)):\n        batch_texts = texts[i:i+batch_size]\n        \n        # Tokenize the input\n        inputs = tokenizer(batch_texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=128).to(device)\n        \n        # Generate translation\n        with torch.no_grad():\n            outputs = model.generate(**inputs, forced_bos_token_id=tokenizer.lang_code_to_id[\"th\"])\n        \n        # Decode the output\n        translations = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n        all_translations.extend(translations)\n    \n    return all_translations","metadata":{"execution":{"iopub.status.busy":"2024-08-04T00:03:13.573210Z","iopub.execute_input":"2024-08-04T00:03:13.573615Z","iopub.status.idle":"2024-08-04T00:03:13.639043Z","shell.execute_reply.started":"2024-08-04T00:03:13.573582Z","shell.execute_reply":"2024-08-04T00:03:13.638112Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"testdf=pd.read_csv('/kaggle/input/north-translation/test (2).csv')\ntestdf","metadata":{"execution":{"iopub.status.busy":"2024-08-04T00:03:23.001846Z","iopub.execute_input":"2024-08-04T00:03:23.002225Z","iopub.status.idle":"2024-08-04T00:03:23.041877Z","shell.execute_reply.started":"2024-08-04T00:03:23.002194Z","shell.execute_reply":"2024-08-04T00:03:23.040946Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"      ID                                           Northern\n0      0  วัน นี้ มี ประ ชุม หัว หน้า บอก ว่า ต้อง เข้า ...\n1      1  ยาย พิศ เปิ้น ตึง เป๋น คน ดี นุ่ง ขาว ห่ม ขาว ...\n2      2  แฟชั่น แบบ ไทย ไทย เฮา ปอ นาง แบบ เตียว ออก มา...\n3      3  น้อง ว่า จะ ไป ฮับ จ้าง ขาย คัว ตี้ กาด แลง จะ...\n4      4  บ่ ว่า แม่ ญิง บ่ ว่า ป้อ จาย บ่า เดี่ยว นี้ ข...\n..   ...                                                ...\n395  395  ย้าง แอ่ว ป่า แอ่ว ดอย ก่อน เปี่ยน มา เข้า วัด...\n396  396  เอา สะ ตัง ก้า พวง มา ลัย ไป นึ่ง ร้อย บาท เอา...\n397  397  จะ ไป ไป สฺว่าย กิ่ง บ่า มุด แฮง กะ เดียว หน่ว...\n398  398  อิ ปี้ ก้า ซื้อ คัว แล้ว นี่ ได้ ปล๋า ดุก ปิ้ง...\n399  399  มะ แลง แม่ จะ ไป แอ่ว หา เปื้อน ตี้ สารภี บ่า ...\n\n[400 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Northern</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>วัน นี้ มี ประ ชุม หัว หน้า บอก ว่า ต้อง เข้า ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>ยาย พิศ เปิ้น ตึง เป๋น คน ดี นุ่ง ขาว ห่ม ขาว ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>แฟชั่น แบบ ไทย ไทย เฮา ปอ นาง แบบ เตียว ออก มา...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>น้อง ว่า จะ ไป ฮับ จ้าง ขาย คัว ตี้ กาด แลง จะ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>บ่ ว่า แม่ ญิง บ่ ว่า ป้อ จาย บ่า เดี่ยว นี้ ข...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>395</th>\n      <td>395</td>\n      <td>ย้าง แอ่ว ป่า แอ่ว ดอย ก่อน เปี่ยน มา เข้า วัด...</td>\n    </tr>\n    <tr>\n      <th>396</th>\n      <td>396</td>\n      <td>เอา สะ ตัง ก้า พวง มา ลัย ไป นึ่ง ร้อย บาท เอา...</td>\n    </tr>\n    <tr>\n      <th>397</th>\n      <td>397</td>\n      <td>จะ ไป ไป สฺว่าย กิ่ง บ่า มุด แฮง กะ เดียว หน่ว...</td>\n    </tr>\n    <tr>\n      <th>398</th>\n      <td>398</td>\n      <td>อิ ปี้ ก้า ซื้อ คัว แล้ว นี่ ได้ ปล๋า ดุก ปิ้ง...</td>\n    </tr>\n    <tr>\n      <th>399</th>\n      <td>399</td>\n      <td>มะ แลง แม่ จะ ไป แอ่ว หา เปื้อน ตี้ สารภี บ่า ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>400 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"northern_thai_texts = list(testdf['Northern'])\n\n# Perform batch translation\ntranslated_texts = batch_translate(northern_thai_texts,batch_size=10)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T00:03:24.269362Z","iopub.execute_input":"2024-08-04T00:03:24.269750Z","iopub.status.idle":"2024-08-04T00:06:06.437097Z","shell.execute_reply.started":"2024-08-04T00:03:24.269718Z","shell.execute_reply":"2024-08-04T00:06:06.436153Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"100%|██████████| 40/40 [02:42<00:00,  4.05s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"testdf['Central'] = translated_texts\ntestdf","metadata":{"execution":{"iopub.status.busy":"2024-08-04T00:06:06.438692Z","iopub.execute_input":"2024-08-04T00:06:06.438994Z","iopub.status.idle":"2024-08-04T00:06:06.451987Z","shell.execute_reply.started":"2024-08-04T00:06:06.438969Z","shell.execute_reply":"2024-08-04T00:06:06.450984Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"      ID                                           Northern  \\\n0      0  วัน นี้ มี ประ ชุม หัว หน้า บอก ว่า ต้อง เข้า ...   \n1      1  ยาย พิศ เปิ้น ตึง เป๋น คน ดี นุ่ง ขาว ห่ม ขาว ...   \n2      2  แฟชั่น แบบ ไทย ไทย เฮา ปอ นาง แบบ เตียว ออก มา...   \n3      3  น้อง ว่า จะ ไป ฮับ จ้าง ขาย คัว ตี้ กาด แลง จะ...   \n4      4  บ่ ว่า แม่ ญิง บ่ ว่า ป้อ จาย บ่า เดี่ยว นี้ ข...   \n..   ...                                                ...   \n395  395  ย้าง แอ่ว ป่า แอ่ว ดอย ก่อน เปี่ยน มา เข้า วัด...   \n396  396  เอา สะ ตัง ก้า พวง มา ลัย ไป นึ่ง ร้อย บาท เอา...   \n397  397  จะ ไป ไป สฺว่าย กิ่ง บ่า มุด แฮง กะ เดียว หน่ว...   \n398  398  อิ ปี้ ก้า ซื้อ คัว แล้ว นี่ ได้ ปล๋า ดุก ปิ้ง...   \n399  399  มะ แลง แม่ จะ ไป แอ่ว หา เปื้อน ตี้ สารภี บ่า ...   \n\n                                               Central  \n0    วัน นี้ มี ประ ชุม หัว หน้า บอก ว่า ต้อง เข้า ...  \n1    ยาย พิศ เขา ทั้ง เป็น คน ดี นุ่ง ขาว ห่ม ขาว ข...  \n2    แฟชั่น แบบ ไทย ไทย เรา พอ นาง แบบ เดิน ออก มา ...  \n3    น้อง ว่า จะ ไป รับ จ้าง ขาย ของ ที่ ตลาด เย็น ...  \n4    ไม่ ว่า ผู้ หญิง ไม่ ว่า พ่อ ชาย ตอน นี้ ขี่ ร...  \n..                                                 ...  \n395  ย้าง เที่ยว ป่า เที่ยว ดอย ก่อน เปลี่ยน มา เข้...  \n396  เอา เงิน แต่ พวง มา ลัย ไป หนึ่ง ร้อย บาท เอา ...  \n397  อย่า ไป หา กิ่ง มะ มุด แรง ก็ เดี๋ยว นู่น ที่ ...  \n398  พี่ แต่ ซื้อ ของ แล้ว นี่ ได้ ปลา ดุก ปิ้ง ตรง...  \n399  ตอน เย็น แม่ จะ ไป เที่ยว หา เพื่อน ที่ สารภี ...  \n\n[400 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Northern</th>\n      <th>Central</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>วัน นี้ มี ประ ชุม หัว หน้า บอก ว่า ต้อง เข้า ...</td>\n      <td>วัน นี้ มี ประ ชุม หัว หน้า บอก ว่า ต้อง เข้า ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>ยาย พิศ เปิ้น ตึง เป๋น คน ดี นุ่ง ขาว ห่ม ขาว ...</td>\n      <td>ยาย พิศ เขา ทั้ง เป็น คน ดี นุ่ง ขาว ห่ม ขาว ข...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>แฟชั่น แบบ ไทย ไทย เฮา ปอ นาง แบบ เตียว ออก มา...</td>\n      <td>แฟชั่น แบบ ไทย ไทย เรา พอ นาง แบบ เดิน ออก มา ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>น้อง ว่า จะ ไป ฮับ จ้าง ขาย คัว ตี้ กาด แลง จะ...</td>\n      <td>น้อง ว่า จะ ไป รับ จ้าง ขาย ของ ที่ ตลาด เย็น ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>บ่ ว่า แม่ ญิง บ่ ว่า ป้อ จาย บ่า เดี่ยว นี้ ข...</td>\n      <td>ไม่ ว่า ผู้ หญิง ไม่ ว่า พ่อ ชาย ตอน นี้ ขี่ ร...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>395</th>\n      <td>395</td>\n      <td>ย้าง แอ่ว ป่า แอ่ว ดอย ก่อน เปี่ยน มา เข้า วัด...</td>\n      <td>ย้าง เที่ยว ป่า เที่ยว ดอย ก่อน เปลี่ยน มา เข้...</td>\n    </tr>\n    <tr>\n      <th>396</th>\n      <td>396</td>\n      <td>เอา สะ ตัง ก้า พวง มา ลัย ไป นึ่ง ร้อย บาท เอา...</td>\n      <td>เอา เงิน แต่ พวง มา ลัย ไป หนึ่ง ร้อย บาท เอา ...</td>\n    </tr>\n    <tr>\n      <th>397</th>\n      <td>397</td>\n      <td>จะ ไป ไป สฺว่าย กิ่ง บ่า มุด แฮง กะ เดียว หน่ว...</td>\n      <td>อย่า ไป หา กิ่ง มะ มุด แรง ก็ เดี๋ยว นู่น ที่ ...</td>\n    </tr>\n    <tr>\n      <th>398</th>\n      <td>398</td>\n      <td>อิ ปี้ ก้า ซื้อ คัว แล้ว นี่ ได้ ปล๋า ดุก ปิ้ง...</td>\n      <td>พี่ แต่ ซื้อ ของ แล้ว นี่ ได้ ปลา ดุก ปิ้ง ตรง...</td>\n    </tr>\n    <tr>\n      <th>399</th>\n      <td>399</td>\n      <td>มะ แลง แม่ จะ ไป แอ่ว หา เปื้อน ตี้ สารภี บ่า ...</td>\n      <td>ตอน เย็น แม่ จะ ไป เที่ยว หา เพื่อน ที่ สารภี ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>400 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"sub = testdf[['ID','Central']]\nsub.to_csv('submission_M2M100_1.2_PEFT.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T00:06:06.453328Z","iopub.execute_input":"2024-08-04T00:06:06.453635Z","iopub.status.idle":"2024-08-04T00:06:06.468252Z","shell.execute_reply.started":"2024-08-04T00:06:06.453609Z","shell.execute_reply":"2024-08-04T00:06:06.467377Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}